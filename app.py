import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
import plotly.express as px
import io
import locale

# í•œêµ­ì–´ ìš”ì¼ ì„¤ì •ì„ ìœ„í•´ ë¡œì¼€ì¼ ì„¤ì •
try:
    locale.setlocale(locale.LC_TIME, 'ko_KR.UTF-8')
except locale.Error:
    if 'locale_warning_shown' not in st.session_state:
        st.warning("í•œêµ­ì–´ ë¡œì¼€ì¼(ko_KR.UTF-8)ì„ ì„¤ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìš”ì¼ì´ ì˜ì–´ë¡œ í‘œì‹œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        st.session_state.locale_warning_shown = True

# ----------------------------------------------------------------------
# ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„ í•¨ìˆ˜
# ----------------------------------------------------------------------


@st.cache_data
def load_and_process_data(uploaded_file, k, lambda_param, w_amount, w_freq, w_recency):
    """
    íŒŒì¼ ë¡œë“œë¶€í„° í´ëŸ¬ìŠ¤í„°ë§, ê°€ì¤‘ì¹˜ ê¸°ë°˜ ë“±ê¸‰ ë¶€ì—¬ê¹Œì§€ ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    try:
        uploaded_file.seek(0)
        if uploaded_file.name.endswith('.csv'):
            df_raw = pd.read_csv(uploaded_file, low_memory=False)
        else:
            df_raw = pd.read_excel(uploaded_file)

        if df_raw.empty:
            return None, "ì˜¤ë¥˜: ì—…ë¡œë“œëœ íŒŒì¼ì— ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return None, f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    date_col = next((col for col in df_raw.columns if 'ë‚ ì§œ' in col), 'ë‚ ì§œ')
    book_col = next((col for col in df_raw.columns if 'ë„ì„œëª…' in col), 'ë„ì„œëª…')
    amount_col = next((col for col in df_raw.columns if 'ë°œì£¼ëŸ‰' in col), 'ë°œì£¼ëŸ‰')

    if not all(c in df_raw.columns for c in [date_col, book_col, amount_col]):
        return None, f"ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼('{date_col}', '{book_col}', '{amount_col}') ì¤‘ ì¼ë¶€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    df_raw[date_col] = pd.to_datetime(df_raw[date_col], errors='coerce')
    df_raw.dropna(subset=[date_col, book_col, amount_col], inplace=True)

    df_raw['ë‚ ì§œ_í¬ë§·'] = df_raw[date_col].dt.strftime('%mì›” %dì¼ (%a)')

    agg_df = df_raw.groupby(book_col).agg(
        ì´ë°œì£¼ëŸ‰=(amount_col, 'sum'),
        ë°œì£¼íšŸìˆ˜=(book_col, 'count'),
        ìµœê·¼ë°œì£¼ì¼=(date_col, 'max'),
        ìµœì´ˆë°œì£¼ì¼=(date_col, 'min')
    ).reset_index()

    duration = (agg_df['ìµœê·¼ë°œì£¼ì¼'] - agg_df['ìµœì´ˆë°œì£¼ì¼']).dt.days
    agg_df['í‰ê·  ë°œì£¼ ê°„ê²©'] = np.where(
        agg_df['ë°œì£¼íšŸìˆ˜'] > 1, duration / (agg_df['ë°œì£¼íšŸìˆ˜'] - 1), np.nan)

    def calculate_recency_score(days_diff, max_days, k_val, lambda_val):
        if max_days == 0:
            return 1.0
        scaled_diff = days_diff / max_days
        return 1 / (1 + scaled_diff * k_val) if scaled_diff <= 1 else np.exp(-scaled_diff * lambda_val)

    ê¸°ì¤€ì¼ = agg_df['ìµœê·¼ë°œì£¼ì¼'].max()
    agg_df['ìµœì´ˆë°œì£¼í›„ê²½ê³¼ì¼'] = (ê¸°ì¤€ì¼ - agg_df['ìµœì´ˆë°œì£¼ì¼']).dt.days
    agg_df['ê²½ê³¼ì¼'] = (ê¸°ì¤€ì¼ - agg_df['ìµœê·¼ë°œì£¼ì¼']).dt.days
    max_days = agg_df['ê²½ê³¼ì¼'].max()
    agg_df['ì‹œê°„ê°€ì¤‘ì¹˜'] = agg_df['ê²½ê³¼ì¼'].apply(
        lambda x: calculate_recency_score(x, max_days, k, lambda_param))

    features = ['ì´ë°œì£¼ëŸ‰', 'ë°œì£¼íšŸìˆ˜', 'ì‹œê°„ê°€ì¤‘ì¹˜']
    scaler = MinMaxScaler()
    agg_df_scaled = agg_df.copy()
    agg_df_scaled[features] = scaler.fit_transform(agg_df_scaled[features])

    kmeans = KMeans(n_clusters=5, init='k-means++',
                    n_init=10, max_iter=300, random_state=42)
    agg_df['Cluster'] = kmeans.fit_predict(agg_df_scaled[features])

    centroids_df_normalized = pd.DataFrame(
        kmeans.cluster_centers_, columns=features)
    rank_score_series = (w_amount * centroids_df_normalized['ì´ë°œì£¼ëŸ‰'] +
                         w_freq * centroids_df_normalized['ë°œì£¼íšŸìˆ˜'] +
                         w_recency * centroids_df_normalized['ì‹œê°„ê°€ì¤‘ì¹˜'])
    centroids_df_normalized['rank_score'] = rank_score_series

    sorted_clusters = centroids_df_normalized['rank_score'].sort_values(
        ascending=False).index

    grade_map = {cluster_id: f"{i+1}ë“±ê¸‰" for i,
                 cluster_id in enumerate(sorted_clusters)}
    score_map = {cluster_id: score for cluster_id,
                 score in zip(sorted_clusters, [5, 4, 3, 2, 1])}
    agg_df['ë“±ê¸‰'] = agg_df['Cluster'].map(grade_map)
    agg_df['ì ìˆ˜'] = agg_df['Cluster'].map(score_map)

    return agg_df, df_raw


def to_excel(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='analysis_result')
    return output.getvalue()


# ----------------------------------------------------------------------
# Streamlit ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ UI
# ----------------------------------------------------------------------
st.set_page_config(layout="wide", page_title="ë„ì„œ ë°œì£¼ ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
st.title("ğŸ“š ë„ì„œ ë°œì£¼ ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

with st.sidebar:
    st.header("âš™ï¸ 1. ë¶„ì„ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader(
        "CSV ë˜ëŠ” XLSX ë°œì£¼ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["csv", "xlsx"])

    if uploaded_file:
        time_span_days = get_date_range(uploaded_file)
        if time_span_days <= 7:
            k_default, lambda_default, period_text = 7.0, 0.5, "1ì£¼ì¼ ì´ë‚´ (ë§¤ìš° ë¯¼ê°)"
        elif time_span_days <= 31:
            k_default, lambda_default, period_text = 5.0, 0.7, "1ê°œì›” ì´ë‚´ (ë¯¼ê°)"
        elif time_span_days <= 182:
            k_default, lambda_default, period_text = 2.0, 1.0, "6ê°œì›” ì´ë‚´ (ë³´í†µ)"
        elif time_span_days <= 365:
            k_default, lambda_default, period_text = 1.0, 1.5, "1ë…„ ì´ë‚´ (í‘œì¤€)"
        else:
            k_default, lambda_default, period_text = 0.5, 2.0, "1ë…„ ì´ìƒ (ë‘”ê°)"

        st.header("âš™ï¸ 2. ë¶„ì„ ë¯¼ê°ë„ ì„¤ì •")
        st.info(f"ë°ì´í„° ê¸°ê°„: **{period_text}**")
        k_param = st.slider("ìµœì‹ ì„± ë¯¼ê°ë„ (k)", 0.1, 10.0, k_default, 0.1)
        lambda_param = st.slider(
            "ì¥ê¸° ë¹„í™œì„± íŒ¨ë„í‹° (Î»)", 0.1, 10.0, lambda_default, 0.1)

        st.header("âš™ï¸ 3. ë“±ê¸‰ ê²°ì • ì¤‘ìš”ë„ ì„¤ì •")
        w_amount = st.slider("ì´ë°œì£¼ëŸ‰ ì¤‘ìš”ë„", 1, 5, 4)
        w_freq = st.slider("ë°œì£¼íšŸìˆ˜ ì¤‘ìš”ë„", 1, 5, 4)
        w_recency = st.slider("ì‹œê°„ê°€ì¤‘ì¹˜ ì¤‘ìš”ë„", 1, 5, 2)

        run_button = st.button("ğŸš€ ë¶„ì„ ì‹¤í–‰", type="primary",
                               use_container_width=True)

if 'run_button' not in st.session_state:
    st.session_state.run_button = False

if not uploaded_file:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
elif run_button:
    with st.spinner('ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...'):
        agg_df, df_raw_or_error = load_and_process_data(
            uploaded_file, k_param, lambda_param, w_amount, w_freq, w_recency)
        if agg_df is not None:
            st.session_state.run_button = True
            st.session_state.agg_df = agg_df
            st.session_state.df_raw = df_raw_or_error
            st.rerun()
        else:
            st.error(df_raw_or_error)
            st.session_state.run_button = False
elif st.session_state.run_button:
    agg_df = st.session_state.agg_df
    df_raw = st.session_state.df_raw

    st.success(f"âœ… **{uploaded_file.name}** íŒŒì¼ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    tab1, tab2, tab3, tab4 = st.tabs(
        ["[ ğŸ“ˆ ë“±ê¸‰ ìš”ì•½ ]", "[ ğŸŒŸ ìœ ë§ ë„ì„œ ë°œêµ´ ]", "[ ğŸ“Š ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ]", "[ ğŸ“‹ ì „ì²´ ë°ì´í„° ]"])

    with tab1:
        st.header("ë“±ê¸‰ë³„ ìš”ì•½")
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("â‘  ë“±ê¸‰ë³„ ë„ì„œ ë¶„í¬")
            grade_order = [f"{i}ë“±ê¸‰" for i in range(1, 6)]
            grade_counts = agg_df['ë“±ê¸‰'].value_counts().reindex(
                grade_order).reset_index()
            fig_bar = px.bar(grade_counts, x='ë“±ê¸‰', y='count', color='ë“±ê¸‰', text_auto=True, category_orders={"ë“±ê¸‰": grade_order},
                             color_discrete_map={'1ë“±ê¸‰': '#0081CF', '2ë“±ê¸‰': '#00A1E0', '3ë“±ê¸‰': '#7ECEF4', '4ë“±ê¸‰': '#B1DFF7', '5ë“±ê¸‰': '#CCCCCC'}, title="í¬íŠ¸í´ë¦¬ì˜¤ ë“±ê¸‰ë³„ ë„ì„œ ìˆ˜")
            st.plotly_chart(fig_bar, use_container_width=True)

        with col2:
            st.subheader("â‘¡ ë“±ê¸‰ë³„ ì˜ë¯¸ì™€ ì „ëµ")
            st.markdown("""
            | ë“±ê¸‰ | ì˜ë¯¸ ë° ìƒíƒœ | ì¶”ì²œ ì „ëµ |
            | :---: | :--- | :--- |
            | **1ë“±ê¸‰** | ë°œì£¼ëŸ‰, íšŸìˆ˜, ìµœì‹ ì„± ë“± í•µì‹¬ ì§€í‘œë“¤ì´ ê°€ì¥ ìš°ìˆ˜í•œ **ìµœìƒìœ„ í•µì‹¬ ê·¸ë£¹** | **ì¬ê³  ìµœìš°ì„  í™•ë³´**, í”„ë¡œëª¨ì…˜/ê´‘ê³  ë“± ì ê·¹ì ì¸ ë§ˆì¼€íŒ… |
            | **2ë“±ê¸‰** | ë§¤ì¶œì˜ í•µì‹¬ì„ ë‹´ë‹¹í•˜ê³  ìˆëŠ” ê¾¸ì¤€í•œ **ìš°ìˆ˜ ê·¸ë£¹** | **ì•ˆì •ì ì¸ ì¬ê³  ìˆ˜ì¤€ ìœ ì§€**, í¬ë¡œìŠ¤ì…€ë§ ì—°ê³„ |
            | **3ë“±ê¸‰** | ì„±ê³¼ê°€ ì¤‘ê°„ ì •ë„ì¸ ê·¸ë£¹, **ì„±ì¥ ë˜ëŠ” í•˜ë½ ê°€ëŠ¥ì„±** ë³´ìœ  | íŒë§¤ ë°ì´í„° ê¸°ë°˜ ìˆ˜ìš” ì˜ˆì¸¡, íŒë§¤ ì´‰ì§„ ì „ëµ ê³ ë¯¼ |
            | **4ë“±ê¸‰** | ë°œì£¼ê°€ ëœ¸í•˜ê±°ë‚˜ ê°ì†Œ ì¶”ì„¸ì¸ **ì£¼ì˜ ê·¸ë£¹** | **ì¬ê³  ìµœì†Œí™”**, ë°œì£¼ ê°ì†Œ ì›ì¸ ë¶„ì„ (ê³„ì ˆì„±, ê²½ìŸ ë“±) |
            | **5ë“±ê¸‰** | ì‚¬ì‹¤ìƒ ë°œì£¼ê°€ ì—†ëŠ” **ë¹„í™œì„±/ê´€ë¦¬ ê·¸ë£¹** | **ì¬ê³  ì²˜ë¶„ ê³ ë ¤ (ì´ë²¤íŠ¸, í• ì¸)**, ì‚¬ì‹¤ìƒ ë‹¨ì¢… ê²€í†  |
            """)
    with tab2:
        st.header("ğŸŒŸ ì‹ ê·œ ìœ ë§ ë„ì„œ ë°œêµ´")
        st.info("ì•„ë˜ ì¡°ê±´ì„ ì¡°ì ˆí•˜ì—¬ 'ìƒˆë¡­ê³ , ê¾¸ì¤€í•œ' ìœ ë§ ë„ì„œë¥¼ ì§ì ‘ ì°¾ì•„ë³´ì„¸ìš”.")

        col1, col2 = st.columns(2)
        with col1:
            max_days_since_first = int(agg_df['ìµœì´ˆë°œì£¼í›„ê²½ê³¼ì¼'].max())
            days_since_first_limit = st.slider(
                "ì¶œì‹œ ê¸°ê°„ í•„í„° (ì¼)", 0, max_days_since_first, min(180, max_days_since_first))
        with col2:
            min_freq_limit = st.slider(
                "ìµœì†Œ ë°œì£¼ íšŸìˆ˜ í•„í„°", 1, int(agg_df['ë°œì£¼íšŸìˆ˜'].max()), 3)

        col3, col4 = st.columns(2)
        with col3:
            max_interval = int(agg_df['í‰ê·  ë°œì£¼ ê°„ê²©'].dropna().max(
            )) if not agg_df['í‰ê·  ë°œì£¼ ê°„ê²©'].isna().all() else 90
            interval_limit = st.slider(
                "ìµœëŒ€ í‰ê·  ë°œì£¼ ê°„ê²© í•„í„°", 1, max_interval, min(30, max_interval))
        with col4:
            min_amount_limit = st.slider(
                "ìµœì†Œ ì´ ë°œì£¼ëŸ‰ í•„í„°", 0, int(agg_df['ì´ë°œì£¼ëŸ‰'].max()), 10)

        promising_books_df = agg_df[
            (agg_df['ìµœì´ˆë°œì£¼í›„ê²½ê³¼ì¼'] <= days_since_first_limit) &
            (agg_df['ë°œì£¼íšŸìˆ˜'] >= min_freq_limit) &
            (agg_df['í‰ê·  ë°œì£¼ ê°„ê²©'].fillna(interval_limit + 1) <= interval_limit) &
            (agg_df['ì´ë°œì£¼ëŸ‰'] >= min_amount_limit)
        ].sort_values(by='í‰ê·  ë°œì£¼ ê°„ê²©')

        st.subheader(f"í•„í„°ë§ ê²°ê³¼: ì´ {len(promising_books_df)}ê¶Œì˜ ìœ ë§ ë„ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

        book_col_name = next(
            (col for col in df_raw.columns if 'ë„ì„œëª…' in col), 'ë„ì„œëª…')
        book_list = ["- ë„ì„œ ì„ íƒ -"] + promising_books_df[book_col_name].tolist()
        selected_book = st.selectbox("ì¶”ì´ ê·¸ë˜í”„ë¥¼ ë³¼ ë„ì„œë¥¼ ì„ íƒí•˜ì„¸ìš”:", book_list)

        if selected_book != "- ë„ì„œ ì„ íƒ -":
            history_df = df_raw[df_raw[book_col_name] == selected_book].copy()
            daily_history = history_df.groupby('ë‚ ì§œ_í¬ë§·').agg(
                ë°œì£¼ëŸ‰=(next(col for col in df_raw.columns if 'ë°œì£¼ëŸ‰' in col), 'sum'),
                ë‚ ì§œ=(next(col for col in df_raw.columns if 'ë‚ ì§œ' in col), 'min')
            ).reset_index().sort_values(by='ë‚ ì§œ')

            fig = px.line(daily_history, x='ë‚ ì§œ_í¬ë§·', y='ë°œì£¼ëŸ‰',
                          title=f"'{selected_book}' ì¼ë³„ ë°œì£¼ëŸ‰ ì¶”ì´", markers=True)
            fig.update_layout(yaxis_title="ë°œì£¼ëŸ‰", xaxis_title="ë‚ ì§œ")
            st.plotly_chart(fig, use_container_width=True)

    with tab3:
        st.header("ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ì‹œê°í™”")
        date_col = next((col for col in df_raw.columns if 'ë‚ ì§œ' in col), 'ë‚ ì§œ')
        amount_col = next(
            (col for col in df_raw.columns if 'ë°œì£¼ëŸ‰' in col), 'ë°œì£¼ëŸ‰')

        # --- ì‹œê°í™” íƒ­ êµ¬ì¡° ìˆ˜ì • ---
        viz_tab1, viz_tab2, viz_tab3, viz_tab4 = st.tabs(
            ["ì „ì²´ ë°œì£¼ í˜„í™©", "ì›”ë³„ ë°œì£¼ í˜„í™©", "ì£¼ë³„ ë°œì£¼ í˜„í™©", "ì¼ë³„ ë°œì£¼ í˜„í™©"])

        with viz_tab1:
            st.subheader("ì£¼ìš” íŠ¸ë Œë“œ ìš”ì•½")
            col1, col2 = st.columns(2)
            with col1:
                monthly_orders = df_raw.groupby(pd.Grouper(key=date_col, freq='ME')).agg(
                    í•©ê³„=(amount_col, 'sum')).reset_index()
                monthly_orders['ë‚ ì§œ_í¬ë§·'] = monthly_orders[date_col].dt.strftime(
                    '%Yë…„ %mì›”')
                fig_month = px.line(monthly_orders, x='ë‚ ì§œ_í¬ë§·',
                                    y='í•©ê³„', title="ì›”ë³„ ì´ ë°œì£¼ëŸ‰", markers=True)
                st.plotly_chart(fig_month, use_container_width=True)
            with col2:
                weekly_orders = df_raw.groupby(pd.Grouper(
                    key=date_col, freq='W-MON')).agg(í•©ê³„=(amount_col, 'sum')).reset_index()
                weekly_orders['ë‚ ì§œ_í¬ë§·'] = weekly_orders[date_col].dt.strftime(
                    '%mì›” %dì¼')
                fig_week = px.line(weekly_orders, x='ë‚ ì§œ_í¬ë§·',
                                   y='í•©ê³„', title="ì£¼ë³„ ì´ ë°œì£¼ëŸ‰", markers=True)
                st.plotly_chart(fig_week, use_container_width=True)

        with viz_tab2:
            st.subheader("ì›”ë³„ ì´ ë°œì£¼ëŸ‰ ìƒì„¸")
            monthly_orders = df_raw.groupby(pd.Grouper(key=date_col, freq='ME')).agg(
                í•©ê³„=(amount_col, 'sum')).reset_index()
            monthly_orders['ë‚ ì§œ_í¬ë§·'] = monthly_orders[date_col].dt.strftime(
                '%Yë…„ %mì›”')
            fig_month_detail = px.bar(
                monthly_orders, x='ë‚ ì§œ_í¬ë§·', y='í•©ê³„', title="ì›”ë³„ ì´ ë°œì£¼ëŸ‰ (ìƒì„¸)", text_auto=True)
            st.plotly_chart(fig_month_detail, use_container_width=True)

        with viz_tab3:
            st.subheader("ì£¼ë³„ ì´ ë°œì£¼ëŸ‰ ìƒì„¸")
            weekly_orders = df_raw.groupby(pd.Grouper(
                key=date_col, freq='W-MON')).agg(í•©ê³„=(amount_col, 'sum')).reset_index()
            weekly_orders['ë‚ ì§œ_í¬ë§·'] = weekly_orders[date_col].dt.strftime(
                '%Y-%m-%d')
            fig_week_detail = px.bar(
                weekly_orders, x='ë‚ ì§œ_í¬ë§·', y='í•©ê³„', title="ì£¼ë³„ ì´ ë°œì£¼ëŸ‰ (ìƒì„¸)", text_auto='.2s')
            st.plotly_chart(fig_week_detail, use_container_width=True)

        with viz_tab4:
            st.subheader("ì¼ë³„ ì´ ë°œì£¼ëŸ‰ ìƒì„¸")
            daily_orders = df_raw.groupby('ë‚ ì§œ_í¬ë§·').agg(í•©ê³„=(amount_col, 'sum'), ë‚ ì§œ=(
                date_col, 'min')).reset_index().sort_values(by='ë‚ ì§œ')
            fig_day_detail = px.line(
                daily_orders, x='ë‚ ì§œ_í¬ë§·', y='í•©ê³„', title="ì¼ë³„ ì´ ë°œì£¼ëŸ‰")
            fig_day_detail.update_traces(mode="lines+markers")
            st.plotly_chart(fig_day_detail, use_container_width=True)

    with tab4:
        st.header("ì „ì²´ ë¶„ì„ ë°ì´í„°")
        display_columns = ['ë„ì„œëª…', 'ë“±ê¸‰', 'ì ìˆ˜', 'ì´ë°œì£¼ëŸ‰', 'ë°œì£¼íšŸìˆ˜',
                           'ì‹œê°„ê°€ì¤‘ì¹˜', 'í‰ê·  ë°œì£¼ ê°„ê²©', 'ìµœì´ˆë°œì£¼ì¼', 'ìµœê·¼ë°œì£¼ì¼', 'ê²½ê³¼ì¼']
        final_df = agg_df[display_columns].sort_values(
            by='ì ìˆ˜', ascending=False)
        st.dataframe(final_df, use_container_width=True)

        st.subheader("ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
        col1, col2 = st.columns(2)
        with col1:
            csv_data = final_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ’¾ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ", data=csv_data,
                               file_name='book_cluster_analysis.csv', mime='text/csv', use_container_width=True)
        with col2:
            excel_data = to_excel(final_df)
            st.download_button("ğŸ’¾ XLSX íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ", data=excel_data, file_name='book_cluster_analysis.xlsx',
                               mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', use_container_width=True)
else:
    st.info("ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì„¤ì •ì„ ë§ˆì¹œ í›„ 'ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
