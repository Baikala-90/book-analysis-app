import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
import plotly.express as px
import io

# ----------------------------------------------------------------------
# ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„ í•¨ìˆ˜
# ----------------------------------------------------------------------


@st.cache_data
def load_and_process_data(uploaded_file_contents, k, lambda_param, w_amount, w_freq, w_recency):
    """
    íŒŒì¼ ë‚´ìš©ì„ ì…ë ¥ë°›ì•„ ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    Streamlitì˜ íŒŒì¼ ì—…ë¡œë” ê°ì²´ ëŒ€ì‹  íŒŒì¼ì˜ ë°”ì´íŠ¸(bytes) ë‚´ìš©ì„ ì§ì ‘ ë‹¤ë£¹ë‹ˆë‹¤.
    """
    try:
        # íŒŒì¼ ë‚´ìš©ì„ ë©”ëª¨ë¦¬ì—ì„œ ì§ì ‘ ì½ê¸°
        file_extension = st.session_state.file_name.split('.')[-1]
        if file_extension == 'csv':
            df_raw = pd.read_csv(io.BytesIO(
                uploaded_file_contents), low_memory=False)
        else:
            df_raw = pd.read_excel(io.BytesIO(uploaded_file_contents))

        if df_raw.empty:
            return None, "ì˜¤ë¥˜: ì—…ë¡œë“œëœ íŒŒì¼ì— ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return None, f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    # --- ë°ì´í„° ì²˜ë¦¬ ë¡œì§ (ì´ì „ê³¼ ë™ì¼) ---
    date_col = next((col for col in df_raw.columns if 'ë‚ ì§œ' in col), 'ë‚ ì§œ')
    book_col = next((col for col in df_raw.columns if 'ë„ì„œëª…' in col), 'ë„ì„œëª…')
    amount_col = next((col for col in df_raw.columns if 'ë°œì£¼ëŸ‰' in col), 'ë°œì£¼ëŸ‰')

    if not all(c in df_raw.columns for c in [date_col, book_col, amount_col]):
        return None, f"ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼('{date_col}', '{book_col}', '{amount_col}') ì¤‘ ì¼ë¶€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    df_raw[date_col] = pd.to_datetime(df_raw[date_col], errors='coerce')
    df_raw.dropna(subset=[date_col, book_col, amount_col], inplace=True)

    # ì•ˆì •ì ì¸ ìš”ì¼ ë³€í™˜ (í•œêµ­ì–´)
    weekday_map = {"Monday": "ì›”", "Tuesday": "í™”", "Wednesday": "ìˆ˜",
                   "Thursday": "ëª©", "Friday": "ê¸ˆ", "Saturday": "í† ", "Sunday": "ì¼"}
    df_raw['ë‚ ì§œ_í¬ë§·'] = df_raw[date_col].dt.strftime(
        '%mì›” %dì¼') + " (" + df_raw[date_col].dt.day_name().map(weekday_map) + ")"

    agg_df = df_raw.groupby(book_col).agg(
        ì´ë°œì£¼ëŸ‰=(amount_col, 'sum'),
        ë°œì£¼íšŸìˆ˜=(book_col, 'count'),
        ìµœê·¼ë°œì£¼ì¼=(date_col, 'max'),
        ìµœì´ˆë°œì£¼ì¼=(date_col, 'min')
    ).reset_index()

    duration = (agg_df['ìµœê·¼ë°œì£¼ì¼'] - agg_df['ìµœì´ˆë°œì£¼ì¼']).dt.days
    agg_df['í‰ê·  ë°œì£¼ ê°„ê²©'] = np.where(
        agg_df['ë°œì£¼íšŸìˆ˜'] > 1, duration / (agg_df['ë°œì£¼íšŸìˆ˜'] - 1), np.nan)

    def calculate_recency_score(days_diff, max_days, k_val, lambda_val):
        if max_days == 0:
            return 1.0
        scaled_diff = days_diff / max_days
        return 1 / (1 + scaled_diff * k_val) if scaled_diff <= 1 else np.exp(-scaled_diff * lambda_val)

    ê¸°ì¤€ì¼ = agg_df['ìµœê·¼ë°œì£¼ì¼'].max()
    agg_df['ìµœì´ˆë°œì£¼í›„ê²½ê³¼ì¼'] = (ê¸°ì¤€ì¼ - agg_df['ìµœì´ˆë°œì£¼ì¼']).dt.days
    agg_df['ê²½ê³¼ì¼'] = (ê¸°ì¤€ì¼ - agg_df['ìµœê·¼ë°œì£¼ì¼']).dt.days
    max_days = agg_df['ê²½ê³¼ì¼'].max()
    agg_df['ì‹œê°„ê°€ì¤‘ì¹˜'] = agg_df['ê²½ê³¼ì¼'].apply(
        lambda x: calculate_recency_score(x, max_days, k, lambda_param))

    features = ['ì´ë°œì£¼ëŸ‰', 'ë°œì£¼íšŸìˆ˜', 'ì‹œê°„ê°€ì¤‘ì¹˜']
    scaler = MinMaxScaler()
    agg_df_scaled = agg_df.copy()
    agg_df_scaled[features] = scaler.fit_transform(agg_df_scaled[features])

    kmeans = KMeans(n_clusters=5, init='k-means++',
                    n_init=10, max_iter=300, random_state=42)
    agg_df['Cluster'] = kmeans.fit_predict(agg_df_scaled[features])

    centroids_df_normalized = pd.DataFrame(
        kmeans.cluster_centers_, columns=features)
    rank_score_series = (w_amount * centroids_df_normalized['ì´ë°œì£¼ëŸ‰'] +
                         w_freq * centroids_df_normalized['ë°œì£¼íšŸìˆ˜'] +
                         w_recency * centroids_df_normalized['ì‹œê°„ê°€ì¤‘ì¹˜'])
    centroids_df_normalized['rank_score'] = rank_score_series

    sorted_clusters = centroids_df_normalized['rank_score'].sort_values(
        ascending=False).index

    grade_map = {cluster_id: f"{i+1}ë“±ê¸‰" for i,
                 cluster_id in enumerate(sorted_clusters)}
    score_map = {cluster_id: score for cluster_id,
                 score in zip(sorted_clusters, [5, 4, 3, 2, 1])}
    agg_df['ë“±ê¸‰'] = agg_df['Cluster'].map(grade_map)
    agg_df['ì ìˆ˜'] = agg_df['Cluster'].map(score_map)

    return agg_df, df_raw


def to_excel(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='analysis_result')
    return output.getvalue()


# ----------------------------------------------------------------------
# Streamlit ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ UI
# ----------------------------------------------------------------------
st.set_page_config(layout="wide", page_title="ë„ì„œ ë°œì£¼ ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
st.title("ğŸ“š ë„ì„œ ë°œì£¼ ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if 'analysis_done' not in st.session_state:
    st.session_state.analysis_done = False

# --- ì‚¬ì´ë“œë°” UI ---
with st.sidebar:
    st.header("âš™ï¸ 1. ë¶„ì„ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader(
        "CSV ë˜ëŠ” XLSX ë°œì£¼ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["csv", "xlsx"])

    # íŒŒì¼ì´ ì—…ë¡œë“œ ë˜ë©´ ë‚˜ë¨¸ì§€ UI í‘œì‹œ
    if uploaded_file:
        # íŒŒì¼ì´ ë³€ê²½ë˜ë©´ ë¶„ì„ ìƒíƒœ ì´ˆê¸°í™”
        if 'file_name' not in st.session_state or st.session_state.file_name != uploaded_file.name:
            st.session_state.analysis_done = False
            st.session_state.file_name = uploaded_file.name
            st.session_state.file_contents = uploaded_file.getvalue()

        # ë°ì´í„° ê¸°ê°„ ê³„ì‚°
        try:
            date_col_name = 'ë‚ ì§œ'
            if st.session_state.file_name.endswith('.csv'):
                df_preview = pd.read_csv(io.BytesIO(
                    st.session_state.file_contents), low_memory=False, usecols=[date_col_name])
            else:
                df_preview = pd.read_excel(io.BytesIO(
                    st.session_state.file_contents), usecols=[date_col_name])
            df_preview[date_col_name] = pd.to_datetime(
                df_preview[date_col_name], errors='coerce').dropna()
            time_span_days = (df_preview[date_col_name].max(
            ) - df_preview[date_col_name].min()).days
        except Exception:
            time_span_days = 365  # ë¯¸ë¦¬ë³´ê¸°ì— ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ê°’

        # ê¸°ê°„ì— ë”°ë¥¸ ê¸°ë³¸ê°’ ì„¤ì •
        if time_span_days <= 7:
            k_default, lambda_default, period_text = 7.0, 0.5, "1ì£¼ì¼ ì´ë‚´ (ë§¤ìš° ë¯¼ê°)"
        elif time_span_days <= 31:
            k_default, lambda_default, period_text = 5.0, 0.7, "1ê°œì›” ì´ë‚´ (ë¯¼ê°)"
        elif time_span_days <= 182:
            k_default, lambda_default, period_text = 2.0, 1.0, "6ê°œì›” ì´ë‚´ (ë³´í†µ)"
        elif time_span_days <= 365:
            k_default, lambda_default, period_text = 1.0, 1.5, "1ë…„ ì´ë‚´ (í‘œì¤€)"
        else:
            k_default, lambda_default, period_text = 0.5, 2.0, "1ë…„ ì´ìƒ (ë‘”ê°)"

        st.header("âš™ï¸ 2. ë¶„ì„ ë¯¼ê°ë„ ì„¤ì •")
        st.info(f"ë°ì´í„° ê¸°ê°„: **{period_text}**")
        k_param = st.slider("ìµœì‹ ì„± ë¯¼ê°ë„ (k)", 0.1, 10.0, k_default, 0.1)
        lambda_param = st.slider(
            "ì¥ê¸° ë¹„í™œì„± íŒ¨ë„í‹° (Î»)", 0.1, 10.0, lambda_default, 0.1)

        st.header("âš™ï¸ 3. ë“±ê¸‰ ê²°ì • ì¤‘ìš”ë„ ì„¤ì •")
        w_amount = st.slider("ì´ë°œì£¼ëŸ‰ ì¤‘ìš”ë„", 1, 5, 4)
        w_freq = st.slider("ë°œì£¼íšŸìˆ˜ ì¤‘ìš”ë„", 1, 5, 4)
        w_recency = st.slider("ì‹œê°„ê°€ì¤‘ì¹˜ ì¤‘ìš”ë„", 1, 5, 2)

        # --- ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼ ---
        if st.button("ğŸš€ ë¶„ì„ ì‹¤í–‰", type="primary", use_container_width=True):
            with st.spinner('ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...'):
                agg_df, df_raw_or_error = load_and_process_data(
                    st.session_state.file_contents, k_param, lambda_param, w_amount, w_freq, w_recency)
                if agg_df is not None:
                    st.session_state.analysis_done = True
                    st.session_state.agg_df = agg_df
                    st.session_state.df_raw = df_raw_or_error
                else:
                    st.session_state.analysis_done = False
                    # df_raw_or_error ë³€ìˆ˜ì— ë‹´ê¸´ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
                    st.error(df_raw_or_error)

# --- ë©”ì¸ í™”ë©´ UI ---
if not uploaded_file:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
elif st.session_state.analysis_done:
    # ë¶„ì„ì´ ì™„ë£Œëœ ìƒíƒœì¼ ë•Œë§Œ í™”ë©´ì„ ê·¸ë¦¼
    agg_df = st.session_state.agg_df
    df_raw = st.session_state.df_raw

    st.success(f"âœ… **{st.session_state.file_name}** íŒŒì¼ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    tab1, tab2, tab3, tab4 = st.tabs(
        ["[ ğŸ“ˆ ë“±ê¸‰ ìš”ì•½ ]", "[ ğŸŒŸ ìœ ë§ ë„ì„œ ë°œêµ´ ]", "[ ğŸ“Š ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ]", "[ ğŸ“‹ ì „ì²´ ë°ì´í„° ]"])

    with tab1:
        # ë“±ê¸‰ ìš”ì•½ íƒ­ ë‚´ìš©...
        st.header("ë“±ê¸‰ë³„ ìš”ì•½")
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("â‘  ë“±ê¸‰ë³„ ë„ì„œ ë¶„í¬")
            grade_order = [f"{i}ë“±ê¸‰" for i in range(1, 6)]
            grade_counts = agg_df['ë“±ê¸‰'].value_counts().reindex(
                grade_order).reset_index()
            fig_bar = px.bar(grade_counts, x='ë“±ê¸‰', y='count', color='ë“±ê¸‰', text_auto=True, category_orders={"ë“±ê¸‰": grade_order},
                             color_discrete_map={'1ë“±ê¸‰': '#0081CF', '2ë“±ê¸‰': '#00A1E0', '3ë“±ê¸‰': '#7ECEF4', '4ë“±ê¸‰': '#B1DFF7', '5ë“±ê¸‰': '#CCCCCC'}, title="í¬íŠ¸í´ë¦¬ì˜¤ ë“±ê¸‰ë³„ ë„ì„œ ìˆ˜")
            st.plotly_chart(fig_bar, use_container_width=True)

        with col2:
            st.subheader("â‘¡ ë“±ê¸‰ë³„ ì˜ë¯¸ì™€ ì „ëµ")
            st.markdown("""
            | ë“±ê¸‰ | ì˜ë¯¸ ë° ìƒíƒœ | ì¶”ì²œ ì „ëµ |
            | :---: | :--- | :--- |
            | **1ë“±ê¸‰** | ë°œì£¼ëŸ‰, íšŸìˆ˜, ìµœì‹ ì„± ë“± í•µì‹¬ ì§€í‘œë“¤ì´ ê°€ì¥ ìš°ìˆ˜í•œ **ìµœìƒìœ„ í•µì‹¬ ê·¸ë£¹** | **ì¬ê³  ìµœìš°ì„  í™•ë³´**, í”„ë¡œëª¨ì…˜/ê´‘ê³  ë“± ì ê·¹ì ì¸ ë§ˆì¼€íŒ… |
            | **2ë“±ê¸‰** | ë§¤ì¶œì˜ í•µì‹¬ì„ ë‹´ë‹¹í•˜ê³  ìˆëŠ” ê¾¸ì¤€í•œ **ìš°ìˆ˜ ê·¸ë£¹** | **ì•ˆì •ì ì¸ ì¬ê³  ìˆ˜ì¤€ ìœ ì§€**, í¬ë¡œìŠ¤ì…€ë§ ì—°ê³„ |
            | **3ë“±ê¸‰** | ì„±ê³¼ê°€ ì¤‘ê°„ ì •ë„ì¸ ê·¸ë£¹, **ì„±ì¥ ë˜ëŠ” í•˜ë½ ê°€ëŠ¥ì„±** ë³´ìœ  | íŒë§¤ ë°ì´í„° ê¸°ë°˜ ìˆ˜ìš” ì˜ˆì¸¡, íŒë§¤ ì´‰ì§„ ì „ëµ ê³ ë¯¼ |
            | **4ë“±ê¸‰** | ë°œì£¼ê°€ ëœ¸í•˜ê±°ë‚˜ ê°ì†Œ ì¶”ì„¸ì¸ **ì£¼ì˜ ê·¸ë£¹** | **ì¬ê³  ìµœì†Œí™”**, ë°œì£¼ ê°ì†Œ ì›ì¸ ë¶„ì„ (ê³„ì ˆì„±, ê²½ìŸ ë“±) |
            | **5ë“±ê¸‰** | ì‚¬ì‹¤ìƒ ë°œì£¼ê°€ ì—†ëŠ” **ë¹„í™œì„±/ê´€ë¦¬ ê·¸ë£¹** | **ì¬ê³  ì²˜ë¶„ ê³ ë ¤ (ì´ë²¤íŠ¸, í• ì¸)**, ì‚¬ì‹¤ìƒ ë‹¨ì¢… ê²€í†  |
            """)
    with tab2:
        # ìœ ë§ ë„ì„œ ë°œêµ´ íƒ­ ë‚´ìš©...
        st.header("ğŸŒŸ ì‹ ê·œ ìœ ë§ ë„ì„œ ë°œêµ´")
        book_col_name = next(
            (col for col in df_raw.columns if 'ë„ì„œëª…' in col), 'ë„ì„œëª…')

        col1, col2 = st.columns(2)
        with col1:
            days_since_first_limit = st.slider("ì¶œì‹œ ê¸°ê°„ í•„í„° (ì¼)", 0, int(
                agg_df['ìµœì´ˆë°œì£¼í›„ê²½ê³¼ì¼'].max()), min(180, int(agg_df['ìµœì´ˆë°œì£¼í›„ê²½ê³¼ì¼'].max())))
        with col2:
            min_freq_limit = st.slider(
                "ìµœì†Œ ë°œì£¼ íšŸìˆ˜ í•„í„°", 1, int(agg_df['ë°œì£¼íšŸìˆ˜'].max()), 3)

        col3, col4 = st.columns(2)
        with col3:
            max_interval = int(agg_df['í‰ê·  ë°œì£¼ ê°„ê²©'].dropna().max(
            )) if not agg_df['í‰ê·  ë°œì£¼ ê°„ê²©'].isna().all() else 90
            interval_limit = st.slider(
                "ìµœëŒ€ í‰ê·  ë°œì£¼ ê°„ê²© í•„í„°", 1, max_interval, min(30, max_interval))
        with col4:
            min_amount_limit = st.slider(
                "ìµœì†Œ ì´ ë°œì£¼ëŸ‰ í•„í„°", 0, int(agg_df['ì´ë°œì£¼ëŸ‰'].max()), 10)

        promising_books_df = agg_df[
            (agg_df['ìµœì´ˆë°œì£¼í›„ê²½ê³¼ì¼'] <= days_since_first_limit) &
            (agg_df['ë°œì£¼íšŸìˆ˜'] >= min_freq_limit) &
            (agg_df['í‰ê·  ë°œì£¼ ê°„ê²©'].fillna(interval_limit + 1) <= interval_limit) &
            (agg_df['ì´ë°œì£¼ëŸ‰'] >= min_amount_limit)
        ].sort_values(by='í‰ê·  ë°œì£¼ ê°„ê²©')

        st.subheader(f"í•„í„°ë§ ê²°ê³¼: ì´ {len(promising_books_df)}ê¶Œì˜ ìœ ë§ ë„ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

        book_list = ["- ë„ì„œ ì„ íƒ -"] + promising_books_df[book_col_name].tolist()
        selected_book = st.selectbox("ì¶”ì´ ê·¸ë˜í”„ë¥¼ ë³¼ ë„ì„œë¥¼ ì„ íƒí•˜ì„¸ìš”:", book_list)

        if selected_book != "- ë„ì„œ ì„ íƒ -":
            history_df = df_raw[df_raw[book_col_name] == selected_book].copy()
            daily_history = history_df.groupby('ë‚ ì§œ_í¬ë§·').agg(
                ë°œì£¼ëŸ‰=(next(col for col in df_raw.columns if 'ë°œì£¼ëŸ‰' in col), 'sum'),
                ë‚ ì§œ=(next(col for col in df_raw.columns if 'ë‚ ì§œ' in col), 'min')
            ).reset_index().sort_values(by='ë‚ ì§œ')

            fig = px.line(daily_history, x='ë‚ ì§œ_í¬ë§·', y='ë°œì£¼ëŸ‰',
                          title=f"'{selected_book}' ì¼ë³„ ë°œì£¼ëŸ‰ ì¶”ì´", markers=True)
            st.plotly_chart(fig, use_container_width=True)

    with tab3:
        # ë°ì´í„° ì¸ì‚¬ì´íŠ¸ íƒ­ ë‚´ìš©...
        st.header("ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ì‹œê°í™”")
        date_col = next((col for col in df_raw.columns if 'ë‚ ì§œ' in col), 'ë‚ ì§œ')
        amount_col = next(
            (col for col in df_raw.columns if 'ë°œì£¼ëŸ‰' in col), 'ë°œì£¼ëŸ‰')

        viz_tab1, viz_tab2, viz_tab3 = st.tabs(
            ["ì›”ë³„ ë°œì£¼ í˜„í™©", "ì£¼ë³„ ë°œì£¼ í˜„í™©", "ì¼ë³„ ë°œì£¼ í˜„í™©"])

        with viz_tab1:
            st.subheader("ì›”ë³„ ì´ ë°œì£¼ëŸ‰")
            monthly_orders = df_raw.groupby(pd.Grouper(key=date_col, freq='ME')).agg(
                í•©ê³„=(amount_col, 'sum')).reset_index()
            monthly_orders['ë‚ ì§œ_í¬ë§·'] = monthly_orders[date_col].dt.strftime(
                '%Yë…„ %mì›”')
            fig_month = px.line(monthly_orders, x='ë‚ ì§œ_í¬ë§·',
                                y='í•©ê³„', title="ì›”ë³„ ì´ ë°œì£¼ëŸ‰", markers=True)
            st.plotly_chart(fig_month, use_container_width=True)

        with viz_tab2:
            st.subheader("ì£¼ë³„ ì´ ë°œì£¼ëŸ‰")
            weekly_orders = df_raw.groupby(pd.Grouper(
                key=date_col, freq='W-MON')).agg(í•©ê³„=(amount_col, 'sum')).reset_index()
            weekly_orders['ë‚ ì§œ_í¬ë§·'] = weekly_orders[date_col].dt.strftime(
                '%Yë…„ %mì›” %dì¼')
            fig_week = px.line(weekly_orders, x='ë‚ ì§œ_í¬ë§·',
                               y='í•©ê³„', title="ì£¼ë³„ ì´ ë°œì£¼ëŸ‰", markers=True)
            st.plotly_chart(fig_week, use_container_width=True)

        with viz_tab3:
            st.subheader("ì¼ë³„ ì´ ë°œì£¼ëŸ‰")
            daily_orders = df_raw.groupby('ë‚ ì§œ_í¬ë§·').agg(í•©ê³„=(amount_col, 'sum'), ë‚ ì§œ=(
                date_col, 'min')).reset_index().sort_values(by='ë‚ ì§œ')
            fig_day = px.line(daily_orders, x='ë‚ ì§œ_í¬ë§·',
                              y='í•©ê³„', title="ì¼ë³„ ì´ ë°œì£¼ëŸ‰")
            fig_day.update_traces(mode="lines+markers")
            st.plotly_chart(fig_day, use_container_width=True)

    with tab4:
        # ì „ì²´ ë°ì´í„° íƒ­ ë‚´ìš©...
        st.header("ì „ì²´ ë¶„ì„ ë°ì´í„°")
        display_columns = ['ë„ì„œëª…', 'ë“±ê¸‰', 'ì ìˆ˜', 'ì´ë°œì£¼ëŸ‰', 'ë°œì£¼íšŸìˆ˜',
                           'ì‹œê°„ê°€ì¤‘ì¹˜', 'í‰ê·  ë°œì£¼ ê°„ê²©', 'ìµœì´ˆë°œì£¼ì¼', 'ìµœê·¼ë°œì£¼ì¼', 'ê²½ê³¼ì¼']
        final_df = agg_df[display_columns].sort_values(
            by='ì ìˆ˜', ascending=False)
        st.dataframe(final_df, use_container_width=True)

        st.subheader("ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
        col1, col2 = st.columns(2)
        with col1:
            csv_data = final_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ’¾ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ", data=csv_data,
                               file_name='book_cluster_analysis.csv', mime='text/csv', use_container_width=True)
        with col2:
            excel_data = to_excel(final_df)
            st.download_button("ğŸ’¾ XLSX íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ", data=excel_data, file_name='book_cluster_analysis.xlsx',
                               mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', use_container_width=True)
else:
    # ë¶„ì„ ì‹¤í–‰ ì „ ì´ˆê¸° í™”ë©´
    st.info("ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì„¤ì •ì„ ë§ˆì¹œ í›„ 'ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
