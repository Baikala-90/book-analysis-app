import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
import plotly.express as px
import io

# ----------------------------------------------------------------------
# ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„ í•¨ìˆ˜
# ----------------------------------------------------------------------


@st.cache_data
def load_and_process_data(uploaded_file_contents, k, lambda_param, w_amount, w_freq, w_recency):
    """
    íŒŒì¼ ë‚´ìš©ì„ ìž…ë ¥ë°›ì•„ ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    try:
        file_extension = st.session_state.file_name.split('.')[-1]
        if file_extension == 'csv':
            df_raw = pd.read_csv(io.BytesIO(
                uploaded_file_contents), low_memory=False)
        else:
            df_raw = pd.read_excel(io.BytesIO(uploaded_file_contents))

        if df_raw.empty:
            return None, "ì˜¤ë¥˜: ì—…ë¡œë“œëœ íŒŒì¼ì— ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return None, f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    date_col = next((col for col in df_raw.columns if 'ë‚ ì§œ' in col), 'ë‚ ì§œ')
    book_col = next((col for col in df_raw.columns if 'ë„ì„œëª…' in col), 'ë„ì„œëª…')
    amount_col = next((col for col in df_raw.columns if 'ë°œì£¼ëŸ‰' in col), 'ë°œì£¼ëŸ‰')

    if not all(c in df_raw.columns for c in [date_col, book_col, amount_col]):
        return None, f"ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼('{date_col}', '{book_col}', '{amount_col}') ì¤‘ ì¼ë¶€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    df_raw[date_col] = pd.to_datetime(df_raw[date_col], errors='coerce')
    df_raw.dropna(subset=[date_col, book_col, amount_col], inplace=True)

    weekday_map = {"Monday": "ì›”", "Tuesday": "í™”", "Wednesday": "ìˆ˜",
                   "Thursday": "ëª©", "Friday": "ê¸ˆ", "Saturday": "í† ", "Sunday": "ì¼"}
    df_raw['ë‚ ì§œ_ë¼ë²¨'] = df_raw[date_col].dt.strftime(
        '%mì›” %dì¼') + " (" + df_raw[date_col].dt.day_name().map(weekday_map).fillna('') + ")"

    agg_df = df_raw.groupby(book_col).agg(
        ì´ë°œì£¼ëŸ‰=(amount_col, 'sum'),
        ë°œì£¼íšŸìˆ˜=(book_col, 'count'),
        ìµœê·¼ë°œì£¼ì¼=(date_col, 'max'),
        ìµœì´ˆë°œì£¼ì¼=(date_col, 'min')
    ).reset_index()

    duration = (agg_df['ìµœê·¼ë°œì£¼ì¼'] - agg_df['ìµœì´ˆë°œì£¼ì¼']).dt.days
    agg_df['í‰ê·  ë°œì£¼ ê°„ê²©'] = np.where(
        agg_df['ë°œì£¼íšŸìˆ˜'] > 1, duration / (agg_df['ë°œì£¼íšŸìˆ˜'] - 1), np.nan)

    def calculate_recency_score(days_diff, max_days, k_val, lambda_val):
        if max_days == 0:
            return 1.0
        scaled_diff = days_diff / max_days
        return 1 / (1 + scaled_diff * k_val) if scaled_diff <= 1 else np.exp(-scaled_diff * lambda_val)

    ê¸°ì¤€ì¼ = agg_df['ìµœê·¼ë°œì£¼ì¼'].max()
    agg_df['ìµœì´ˆë°œì£¼í›„ê²½ê³¼ì¼'] = (ê¸°ì¤€ì¼ - agg_df['ìµœì´ˆë°œì£¼ì¼']).dt.days
    agg_df['ê²½ê³¼ì¼'] = (ê¸°ì¤€ì¼ - agg_df['ìµœê·¼ë°œì£¼ì¼']).dt.days
    max_days = agg_df['ê²½ê³¼ì¼'].max()
    agg_df['ì‹œê°„ê°€ì¤‘ì¹˜'] = agg_df['ê²½ê³¼ì¼'].apply(
        lambda x: calculate_recency_score(x, max_days, k, lambda_param))

    features = ['ì´ë°œì£¼ëŸ‰', 'ë°œì£¼íšŸìˆ˜', 'ì‹œê°„ê°€ì¤‘ì¹˜']
    scaler = MinMaxScaler()

    # ì •ê·œí™”ëœ ê°’ì„ ë³„ë„ ì»¬ëŸ¼ìœ¼ë¡œ ì €ìž¥
    norm_features = [f + '_ì •ê·œí™”' for f in features]
    agg_df[norm_features] = scaler.fit_transform(agg_df[features])

    kmeans = KMeans(n_clusters=5, init='k-means++',
                    n_init=10, max_iter=300, random_state=42)
    agg_df['Cluster'] = kmeans.fit_predict(agg_df[norm_features])

    # --- ë“±ê¸‰ ê²°ì • ë¡œì§ (K-Means ê¸°ë°˜) ---
    centroids_df_normalized = pd.DataFrame(
        kmeans.cluster_centers_, columns=norm_features)
    rank_score_series = (w_amount * centroids_df_normalized['ì´ë°œì£¼ëŸ‰_ì •ê·œí™”'] +
                         w_freq * centroids_df_normalized['ë°œì£¼íšŸìˆ˜_ì •ê·œí™”'] +
                         w_recency * centroids_df_normalized['ì‹œê°„ê°€ì¤‘ì¹˜_ì •ê·œí™”'])
    centroids_df_normalized['rank_score'] = rank_score_series
    sorted_clusters = centroids_df_normalized['rank_score'].sort_values(
        ascending=False).index
    grade_map = {cluster_id: f"{i+1}ë“±ê¸‰" for i,
                 cluster_id in enumerate(sorted_clusters)}
    agg_df['ë“±ê¸‰'] = agg_df['Cluster'].map(grade_map)

    # --- ì¢…í•© ì ìˆ˜ ê³„ì‚° ë¡œì§ (ì†Œìˆ˜ì ) ---
    total_weight = w_amount + w_freq + w_recency
    agg_df['ì¢…í•© ì ìˆ˜'] = (
        (w_amount * agg_df['ì´ë°œì£¼ëŸ‰_ì •ê·œí™”'] +
         w_freq * agg_df['ë°œì£¼íšŸìˆ˜_ì •ê·œí™”'] +
         w_recency * agg_df['ì‹œê°„ê°€ì¤‘ì¹˜_ì •ê·œí™”']) / total_weight
    ) * 100

    # ë¶ˆí•„ìš”í•œ ì •ê·œí™” ì»¬ëŸ¼ ì‚­ì œ
    agg_df.drop(columns=norm_features, inplace=True)

    return agg_df, df_raw


def to_excel(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='analysis_result')
    return output.getvalue()


# ----------------------------------------------------------------------
# Streamlit ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ UI
# ----------------------------------------------------------------------
st.set_page_config(layout="wide", page_title="ë„ì„œ ë°œì£¼ ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
st.title("ðŸ“š ë„ì„œ ë°œì£¼ ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

if 'analysis_done' not in st.session_state:
    st.session_state.analysis_done = False

with st.sidebar:
    st.header("âš™ï¸ 1. ë¶„ì„ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader(
        "CSV ë˜ëŠ” XLSX ë°œì£¼ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["csv", "xlsx"])

    if uploaded_file:
        if 'file_name' not in st.session_state or st.session_state.file_name != uploaded_file.name:
            st.session_state.analysis_done = False
            st.session_state.file_name = uploaded_file.name
            st.session_state.file_contents = uploaded_file.getvalue()

        try:
            date_col_name = 'ë‚ ì§œ'
            file_contents_for_preview = io.BytesIO(
                st.session_state.file_contents)
            if st.session_state.file_name.endswith('.csv'):
                df_preview = pd.read_csv(
                    file_contents_for_preview, low_memory=False, usecols=[date_col_name])
            else:
                df_preview = pd.read_excel(
                    file_contents_for_preview, usecols=[date_col_name])
            df_preview[date_col_name] = pd.to_datetime(
                df_preview[date_col_name], errors='coerce').dropna()
            time_span_days = (df_preview[date_col_name].max(
            ) - df_preview[date_col_name].min()).days
        except Exception:
            time_span_days = 365

        if time_span_days <= 7:
            k_default, lambda_default, period_text = 7.0, 0.5, "1ì£¼ì¼ ì´ë‚´"
        elif time_span_days <= 31:
            k_default, lambda_default, period_text = 5.0, 0.7, "1ê°œì›” ì´ë‚´"
        elif time_span_days <= 182:
            k_default, lambda_default, period_text = 2.0, 1.0, "6ê°œì›” ì´ë‚´"
        elif time_span_days <= 365:
            k_default, lambda_default, period_text = 1.0, 1.5, "1ë…„ ì´ë‚´"
        else:
            k_default, lambda_default, period_text = 0.5, 2.0, "1ë…„ ì´ìƒ"

        st.header("âš™ï¸ 2. ë¶„ì„ ë¯¼ê°ë„ ì„¤ì •")
        st.info(f"ë°ì´í„° ê¸°ê°„: **{period_text}**")
        k_param = st.slider("ìµœì‹ ì„± ë¯¼ê°ë„ (k)", 0.1, 10.0, k_default, 0.1)
        lambda_param = st.slider(
            "ìž¥ê¸° ë¹„í™œì„± íŒ¨ë„í‹° (Î»)", 0.1, 10.0, lambda_default, 0.1)

        st.header("âš™ï¸ 3. ë“±ê¸‰/ì ìˆ˜ ì¤‘ìš”ë„ ì„¤ì •")
        w_amount = st.slider("ì´ë°œì£¼ëŸ‰ ì¤‘ìš”ë„", 1, 5, 4)
        w_freq = st.slider("ë°œì£¼íšŸìˆ˜ ì¤‘ìš”ë„", 1, 5, 4)
        w_recency = st.slider("ì‹œê°„ê°€ì¤‘ì¹˜ ì¤‘ìš”ë„", 1, 5, 2)

        if st.button("ðŸš€ ë¶„ì„ ì‹¤í–‰", type="primary", use_container_width=True):
            with st.spinner('ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ìž…ë‹ˆë‹¤...'):
                agg_df, df_raw_or_error = load_and_process_data(
                    st.session_state.file_contents, k_param, lambda_param, w_amount, w_freq, w_recency)
                if agg_df is not None:
                    st.session_state.analysis_done = True
                    st.session_state.agg_df = agg_df
                    st.session_state.df_raw = df_raw_or_error
                else:
                    st.session_state.analysis_done = False
                    st.error(df_raw_or_error)
            st.rerun()

if not uploaded_file:
    st.info("ðŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
elif st.session_state.analysis_done:
    agg_df = st.session_state.agg_df
    df_raw = st.session_state.df_raw

    st.success(f"âœ… **{st.session_state.file_name}** íŒŒì¼ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    tab1, tab2, tab3, tab4 = st.tabs(
        ["[ ðŸ“ˆ ë“±ê¸‰ ìš”ì•½ ]", "[ ðŸŒŸ ìœ ë§ ë„ì„œ ë°œêµ´ ]", "[ ðŸ“Š ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ]", "[ ðŸ“‹ ì „ì²´ ë°ì´í„° ]"])

    with tab1:
        st.header("ë“±ê¸‰ë³„ ìš”ì•½")
        # ... (ì´ì „ ì½”ë“œì™€ ë™ì¼)
    with tab2:
        st.header("ðŸŒŸ ì‹ ê·œ ìœ ë§ ë„ì„œ ë°œêµ´")
        book_col_name = next(
            (col for col in df_raw.columns if 'ë„ì„œëª…' in col), 'ë„ì„œëª…')

        # ... (í•„í„° UI ì´ì „ê³¼ ë™ì¼)
        col1, col2 = st.columns(2)
        # ... (ì´í•˜ í•„í„° UI ì½”ë“œ ìƒëžµ)

        promising_books_df = agg_df[
            # ... (í•„í„°ë§ ë¡œì§ ì´ì „ê³¼ ë™ì¼)
        ]

        st.subheader(f"í•„í„°ë§ ê²°ê³¼: ì´ {len(promising_books_df)}ê¶Œì˜ ìœ ë§ ë„ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

        col_sort1, col_sort2 = st.columns(2)
        with col_sort1:
            sort_by_options = {
                "ì¢…í•© ì ìˆ˜": "ì¢…í•© ì ìˆ˜",  # ì •ë ¬ ê¸°ì¤€ì— 'ì¢…í•© ì ìˆ˜' ì¶”ê°€
                "í‰ê·  ë°œì£¼ ê°„ê²©": "í‰ê·  ë°œì£¼ ê°„ê²©",
                "ì´ë°œì£¼ëŸ‰": "ì´ë°œì£¼ëŸ‰",
                "ë°œì£¼ íšŸìˆ˜": "ë°œì£¼íšŸìˆ˜",
                "ì¶œì‹œì¼": "ìµœì´ˆë°œì£¼í›„ê²½ê³¼ì¼"
            }
            sort_by = st.selectbox(
                "ì •ë ¬ ê¸°ì¤€ ì„ íƒ", options=list(sort_by_options.keys()))
        with col_sort2:
            sort_order = st.selectbox(
                "ì •ë ¬ ìˆœì„œ ì„ íƒ", options=["ë‚´ë¦¼ì°¨ìˆœ", "ì˜¤ë¦„ì°¨ìˆœ"])  # ë‚´ë¦¼ì°¨ìˆœì„ ê¸°ë³¸ìœ¼ë¡œ

        is_ascending = (sort_order == "ì˜¤ë¦„ì°¨ìˆœ")
        promising_books_df = promising_books_df.sort_values(
            by=sort_by_options[sort_by], ascending=is_ascending)

        for _, row in promising_books_df.iterrows():
            book_title = row[book_col_name]
            # expander ì œëª©ì— 'ì¢…í•© ì ìˆ˜' í‘œì‹œ
            with st.expander(f"'{book_title}' (ì¢…í•©ì ìˆ˜: {row['ì¢…í•© ì ìˆ˜']:.2f}ì  / í‰ê·  {row['í‰ê·  ë°œì£¼ ê°„ê²©']:.1f}ì¼ ê°„ê²©)"):
                history_df = df_raw[df_raw[book_col_name] == book_title].copy()
                daily_history = history_df.groupby(next(col for col in history_df.columns if 'ë‚ ì§œ' in col)).agg(
                    ì¼ì¼_ë°œì£¼ëŸ‰=(
                        next(col for col in history_df.columns if 'ë°œì£¼ëŸ‰' in col), 'sum')
                ).reset_index()
                daily_history['ë‚ ì§œ_ë¼ë²¨'] = daily_history[next(
                    col for col in daily_history.columns if 'ë‚ ì§œ' in col)].dt.strftime('%mì›” %dì¼ (%a)')

                fig = px.line(daily_history, x='ë‚ ì§œ_ë¼ë²¨', y='ì¼ì¼_ë°œì£¼ëŸ‰',
                              title=f"'{book_title}' ë°œì£¼ëŸ‰ ì¶”ì´", markers=True)
                fig.update_layout(yaxis_title="ë°œì£¼ëŸ‰", xaxis_title="ë‚ ì§œ")
                st.plotly_chart(fig, use_container_width=True)

    with tab3:
        # ... (ì´ì „ ì½”ë“œì™€ ë™ì¼)
    with tab4:
        st.header("ì „ì²´ ë¶„ì„ ë°ì´í„°")
        # í‘œì‹œ ì»¬ëŸ¼ì— 'ì¢…í•© ì ìˆ˜' ì¶”ê°€, 'ì ìˆ˜' ì œê±°
        display_columns = ['ë„ì„œëª…', 'ë“±ê¸‰', 'ì¢…í•© ì ìˆ˜', 'ì´ë°œì£¼ëŸ‰',
                           'ë°œì£¼íšŸìˆ˜', 'ì‹œê°„ê°€ì¤‘ì¹˜', 'í‰ê·  ë°œì£¼ ê°„ê²©', 'ìµœì´ˆë°œì£¼ì¼', 'ìµœê·¼ë°œì£¼ì¼', 'ê²½ê³¼ì¼']
        # 'ì¢…í•© ì ìˆ˜' ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        final_df = agg_df[display_columns].sort_values(
            by='ì¢…í•© ì ìˆ˜', ascending=False)
        # ì†Œìˆ˜ì  ë‘˜ì§¸ ìžë¦¬ê¹Œì§€ í‘œì‹œ
        st.dataframe(final_df.style.format(
            {'ì¢…í•© ì ìˆ˜': "{:.2f}"}), use_container_width=True)

        st.subheader("ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
        # ... (ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì´ì „ê³¼ ë™ì¼)
else:
    st.info("ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì„¤ì •ì„ ë§ˆì¹œ í›„ 'ë¶„ì„ ì‹¤í–‰' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
