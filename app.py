import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
import plotly.express as px
import io

# ----------------------------------------------------------------------
# ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„ í•¨ìˆ˜
# ----------------------------------------------------------------------


@st.cache_data
def get_date_range(uploaded_file):
    """íŒŒì¼ì„ ê°€ë³ê²Œ ì½ì–´ ë‚ ì§œ ë²”ìœ„(ì „ì²´ ê¸°ê°„)ë§Œ ê³„ì‚°í•©ë‹ˆë‹¤."""
    try:
        uploaded_file.seek(0)
        if uploaded_file.name.endswith('.csv'):
            df_preview = pd.read_csv(
                uploaded_file, low_memory=False, usecols=lambda c: 'ë‚ ì§œ' in c)
        else:
            df_preview = pd.read_excel(
                uploaded_file, usecols=lambda c: 'ë‚ ì§œ' in c)

        date_col = next(
            (col for col in df_preview.columns if 'ë‚ ì§œ' in col), None)
        if not date_col:
            return 0

        df_preview[date_col] = pd.to_datetime(
            df_preview[date_col], errors='coerce').dropna()
        if len(df_preview[date_col]) < 2:
            return 0

        time_span = (df_preview[date_col].max() -
                     df_preview[date_col].min()).days
        uploaded_file.seek(0)
        return time_span
    except Exception:
        return 0


@st.cache_data
def load_and_process_data(uploaded_file, k, lambda_param, w_amount, w_freq, w_recency):
    """
    íŒŒì¼ ë¡œë“œë¶€í„° í´ëŸ¬ìŠ¤í„°ë§, ê°€ì¤‘ì¹˜ ê¸°ë°˜ ë“±ê¸‰ ë¶€ì—¬ê¹Œì§€ ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    try:
        uploaded_file.seek(0)
        if uploaded_file.name.endswith('.csv'):
            df_raw = pd.read_csv(uploaded_file, low_memory=False)
        else:
            df_raw = pd.read_excel(uploaded_file)

        if df_raw.empty:
            st.error("ì˜¤ë¥˜: ì—…ë¡œë“œëœ íŒŒì¼ì— ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return None, None
    except pd.errors.EmptyDataError:
        st.error("ì˜¤ë¥˜: ì—…ë¡œë“œëœ íŒŒì¼ì´ ë¹„ì–´ ìˆê±°ë‚˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return None, None
    except Exception as e:
        st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None, None

    date_col = next((col for col in df_raw.columns if 'ë‚ ì§œ' in col), 'ë‚ ì§œ')
    book_col = next((col for col in df_raw.columns if 'ë„ì„œëª…' in col), 'ë„ì„œëª…')
    amount_col = next((col for col in df_raw.columns if 'ë°œì£¼ëŸ‰' in col), 'ë°œì£¼ëŸ‰')

    if not all(c in df_raw.columns for c in [date_col, book_col, amount_col]):
        st.error(
            f"ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼('{date_col}', '{book_col}', '{amount_col}') ì¤‘ ì¼ë¶€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None

    df_raw[date_col] = pd.to_datetime(df_raw[date_col], errors='coerce')
    df_raw.dropna(subset=[date_col, book_col, amount_col], inplace=True)

    agg_df = df_raw.groupby(book_col).agg(
        ì´ë°œì£¼ëŸ‰=(amount_col, 'sum'),
        ë°œì£¼íšŸìˆ˜=(book_col, 'count'),
        ìµœê·¼ë°œì£¼ì¼=(date_col, 'max'),
        ìµœì´ˆë°œì£¼ì¼=(date_col, 'min')
    ).reset_index()

    duration = (agg_df['ìµœê·¼ë°œì£¼ì¼'] - agg_df['ìµœì´ˆë°œì£¼ì¼']).dt.days
    agg_df['í‰ê·  ë°œì£¼ ê°„ê²©'] = np.where(
        agg_df['ë°œì£¼íšŸìˆ˜'] > 1, duration / (agg_df['ë°œì£¼íšŸìˆ˜'] - 1), np.nan)

    def calculate_recency_score(days_diff, max_days, k_val, lambda_val):
        if max_days == 0:
            return 1.0
        scaled_diff = days_diff / max_days
        return 1 / (1 + scaled_diff * k_val) if scaled_diff <= 1 else np.exp(-scaled_diff * lambda_val)

    ê¸°ì¤€ì¼ = agg_df['ìµœê·¼ë°œì£¼ì¼'].max()
    agg_df['ìµœì´ˆë°œì£¼í›„ê²½ê³¼ì¼'] = (ê¸°ì¤€ì¼ - agg_df['ìµœì´ˆë°œì£¼ì¼']).dt.days
    agg_df['ê²½ê³¼ì¼'] = (ê¸°ì¤€ì¼ - agg_df['ìµœê·¼ë°œì£¼ì¼']).dt.days
    max_days = agg_df['ê²½ê³¼ì¼'].max()
    agg_df['ì‹œê°„ê°€ì¤‘ì¹˜'] = agg_df['ê²½ê³¼ì¼'].apply(
        lambda x: calculate_recency_score(x, max_days, k, lambda_param))

    features = ['ì´ë°œì£¼ëŸ‰', 'ë°œì£¼íšŸìˆ˜', 'ì‹œê°„ê°€ì¤‘ì¹˜']
    scaler = MinMaxScaler()
    agg_df_scaled = agg_df.copy()
    agg_df_scaled[features] = scaler.fit_transform(agg_df_scaled[features])

    kmeans = KMeans(n_clusters=5, init='k-means++',
                    n_init=10, max_iter=300, random_state=42)
    agg_df['Cluster'] = kmeans.fit_predict(agg_df_scaled[features])

    centroids_df_normalized = pd.DataFrame(
        kmeans.cluster_centers_, columns=features)
    rank_score_series = (w_amount * centroids_df_normalized['ì´ë°œì£¼ëŸ‰'] +
                         w_freq * centroids_df_normalized['ë°œì£¼íšŸìˆ˜'] +
                         w_recency * centroids_df_normalized['ì‹œê°„ê°€ì¤‘ì¹˜'])
    centroids_df_normalized['rank_score'] = rank_score_series

    sorted_clusters = centroids_df_normalized['rank_score'].sort_values(
        ascending=False).index

    grade_map = {cluster_id: f"{i+1}ë“±ê¸‰" for i,
                 cluster_id in enumerate(sorted_clusters)}
    score_map = {cluster_id: score for cluster_id,
                 score in zip(sorted_clusters, [5, 4, 3, 2, 1])}
    agg_df['ë“±ê¸‰'] = agg_df['Cluster'].map(grade_map)
    agg_df['ì ìˆ˜'] = agg_df['Cluster'].map(score_map)

    return agg_df, df_raw


def to_excel(df):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='analysis_result')
    return output.getvalue()


# ----------------------------------------------------------------------
# Streamlit ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ UI
# ----------------------------------------------------------------------
st.set_page_config(layout="wide", page_title="ë„ì„œ ë°œì£¼ ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
st.title("ğŸ“š ë„ì„œ ë°œì£¼ ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

with st.sidebar:
    st.header("âš™ï¸ 1. ë¶„ì„ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader(
        "CSV ë˜ëŠ” XLSX ë°œì£¼ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=["csv", "xlsx"])

if not uploaded_file:
    st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    st.stop()

time_span_days = get_date_range(uploaded_file)

if time_span_days <= 7:
    k_default, lambda_default, period_text = 7.0, 0.5, "1ì£¼ì¼ ì´ë‚´ (ë§¤ìš° ë¯¼ê°)"
elif time_span_days <= 31:
    k_default, lambda_default, period_text = 5.0, 0.7, "1ê°œì›” ì´ë‚´ (ë¯¼ê°)"
elif time_span_days <= 182:
    k_default, lambda_default, period_text = 2.0, 1.0, "6ê°œì›” ì´ë‚´ (ë³´í†µ)"
elif time_span_days <= 365:
    k_default, lambda_default, period_text = 1.0, 1.5, "1ë…„ ì´ë‚´ (í‘œì¤€)"
else:
    k_default, lambda_default, period_text = 0.5, 2.0, "1ë…„ ì´ìƒ (ë‘”ê°)"

with st.sidebar:
    st.header("âš™ï¸ 2. ë¶„ì„ ë¯¼ê°ë„ ì„¤ì •")
    st.info(f"ë°ì´í„° ê¸°ê°„: **{period_text}**")
    k_param = st.slider("ìµœì‹ ì„± ë¯¼ê°ë„ (k)", 0.1, 10.0, k_default,
                        0.1, help="ê°’ì´ í´ìˆ˜ë¡ ìµœê·¼ ë°œì£¼ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.")
    lambda_param = st.slider("ì¥ê¸° ë¹„í™œì„± íŒ¨ë„í‹° (Î»)", 0.1, 10.0,
                             lambda_default, 0.1, help="ì´ ê°’ì€ ë§¤ìš° ì˜¤ë˜ëœ ë°ì´í„°ì— ëŒ€í•œ íŒ¨ë„í‹°ë¡œ ì‘ìš©í•©ë‹ˆë‹¤.")

    st.header("âš™ï¸ 3. ë“±ê¸‰ ê²°ì • ì¤‘ìš”ë„ ì„¤ì •")
    st.markdown("ê° ì§€í‘œê°€ ë“±ê¸‰ ê²°ì •ì— ì–¼ë§ˆë‚˜ ì¤‘ìš”í•˜ê²Œ ì‘ìš©í• ì§€ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤.")
    w_amount = st.slider("ì´ë°œì£¼ëŸ‰ ì¤‘ìš”ë„", 1, 5, 4)
    w_freq = st.slider("ë°œì£¼íšŸìˆ˜ ì¤‘ìš”ë„", 1, 5, 4)
    w_recency = st.slider("ì‹œê°„ê°€ì¤‘ì¹˜ ì¤‘ìš”ë„", 1, 5, 2)


agg_df, df_raw = load_and_process_data(
    uploaded_file, k_param, lambda_param, w_amount, w_freq, w_recency)

if agg_df is not None:
    st.success(f"âœ… **{uploaded_file.name}** íŒŒì¼ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    tab1, tab2, tab3, tab4 = st.tabs(
        ["[ ğŸ“ˆ í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ]", "[ ğŸŒŸ ì‹ ê·œ ìœ ë§ ë„ì„œ ë°œêµ´ ]", "[ ğŸ“Š ì¶”ê°€ ì‹œê°í™” ]", "[ ğŸ“‹ ì „ì²´ ë°ì´í„° ]"])

    with tab1:
        # ... (ì´ì „ê³¼ ë™ì¼)
        st.header("K-Means í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ê²°ê³¼")
        grade_order = [f"{i}ë“±ê¸‰" for i in range(1, 6)]
        fig = px.scatter_3d(
            agg_df, x='ì´ë°œì£¼ëŸ‰', y='ë°œì£¼íšŸìˆ˜', z='ì‹œê°„ê°€ì¤‘ì¹˜', color='ë“±ê¸‰',
            color_discrete_map={'1ë“±ê¸‰': '#0081CF', '2ë“±ê¸‰': '#00A1E0',
                                '3ë“±ê¸‰': '#7ECEF4', '4ë“±ê¸‰': '#B1DFF7', '5ë“±ê¸‰': '#CCCCCC'},
            category_orders={"ë“±ê¸‰": grade_order}, hover_name='ë„ì„œëª…',
            hover_data={'ë“±ê¸‰': True, 'ì´ë°œì£¼ëŸ‰': ':.0f', 'ë°œì£¼íšŸìˆ˜': ':.0f',
                        'ìµœì´ˆë°œì£¼ì¼': '%Y-%m-%d', 'í‰ê·  ë°œì£¼ ê°„ê²©': ':.1f', 'ë„ì„œëª…': False},
            title='ì´ë°œì£¼ëŸ‰-ë°œì£¼íšŸìˆ˜-ì‹œê°„ê°€ì¤‘ì¹˜ ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°'
        )
        fig.update_layout(margin=dict(l=0, r=0, b=0, t=40), height=600)
        st.plotly_chart(fig, use_container_width=True)
        with st.expander("â­ ë“±ê¸‰ë³„ ì˜ë¯¸ì™€ ì „ëµ", expanded=True):
            st.markdown("""
            | ë“±ê¸‰ | ì˜ë¯¸ ë° ìƒíƒœ | ì¶”ì²œ ì „ëµ |
            | :---: | :--- | :--- |
            | **1ë“±ê¸‰** | ë°œì£¼ëŸ‰, íšŸìˆ˜, ìµœì‹ ì„± ë“± í•µì‹¬ ì§€í‘œë“¤ì´ ê°€ì¥ ìš°ìˆ˜í•œ **ìµœìƒìœ„ í•µì‹¬ ê·¸ë£¹** | **ì¬ê³  ìµœìš°ì„  í™•ë³´**, í”„ë¡œëª¨ì…˜/ê´‘ê³  ë“± ì ê·¹ì ì¸ ë§ˆì¼€íŒ… |
            | **2ë“±ê¸‰** | ë§¤ì¶œì˜ í•µì‹¬ì„ ë‹´ë‹¹í•˜ê³  ìˆëŠ” ê¾¸ì¤€í•œ **ìš°ìˆ˜ ê·¸ë£¹** | **ì•ˆì •ì ì¸ ì¬ê³  ìˆ˜ì¤€ ìœ ì§€**, í¬ë¡œìŠ¤ì…€ë§ ì—°ê³„ |
            | **3ë“±ê¸‰** | ì„±ê³¼ê°€ ì¤‘ê°„ ì •ë„ì¸ ê·¸ë£¹, **ì„±ì¥ ë˜ëŠ” í•˜ë½ ê°€ëŠ¥ì„±** ë³´ìœ  | íŒë§¤ ë°ì´í„° ê¸°ë°˜ ìˆ˜ìš” ì˜ˆì¸¡, íŒë§¤ ì´‰ì§„ ì „ëµ ê³ ë¯¼ |
            | **4ë“±ê¸‰** | ë°œì£¼ê°€ ëœ¸í•˜ê±°ë‚˜ ê°ì†Œ ì¶”ì„¸ì¸ **ì£¼ì˜ ê·¸ë£¹** | **ì¬ê³  ìµœì†Œí™”**, ë°œì£¼ ê°ì†Œ ì›ì¸ ë¶„ì„ (ê³„ì ˆì„±, ê²½ìŸ ë“±) |
            | **5ë“±ê¸‰** | ì‚¬ì‹¤ìƒ ë°œì£¼ê°€ ì—†ëŠ” **ë¹„í™œì„±/ê´€ë¦¬ ê·¸ë£¹** | **ì¬ê³  ì²˜ë¶„ ê³ ë ¤ (ì´ë²¤íŠ¸, í• ì¸)**, ì‚¬ì‹¤ìƒ ë‹¨ì¢… ê²€í†  |
            """)

    with tab2:
        st.header("ğŸŒŸ ì‹ ê·œ ìœ ë§ ë„ì„œ ë°œêµ´ í•„í„°")
        st.info("ì•„ë˜ ì¡°ê±´ì„ ì¡°ì ˆí•˜ì—¬ 'ìƒˆë¡­ê³ , ê¾¸ì¤€í•œ' ìœ ë§ ë„ì„œë¥¼ ì§ì ‘ ì°¾ì•„ë³´ì„¸ìš”.")

        col1, col2, col3 = st.columns(3)
        with col1:
            max_days_since_first = int(agg_df['ìµœì´ˆë°œì£¼í›„ê²½ê³¼ì¼'].max())
            days_since_first_limit = st.slider("ì¶œì‹œ ê¸°ê°„ í•„í„° (ìµœì´ˆ ë°œì£¼ í›„ ê²½ê³¼ì¼)", 0, max_days_since_first, min(
                180, max_days_since_first), help="ì´ ìŠ¬ë¼ì´ë”ë¡œ ì„¤ì •í•œ ì¼ìˆ˜ ì´ë‚´ì— ìµœì´ˆë¡œ ë°œì£¼ëœ 'ì‹ ìƒ' ë„ì„œë“¤ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.")
        with col2:
            min_freq_limit = st.slider("ìµœì†Œ ë°œì£¼ íšŸìˆ˜ í•„í„°", 1, int(
                agg_df['ë°œì£¼íšŸìˆ˜'].max()), 3, help="ì ì–´ë„ ì—¬ê¸°ì„œ ì„¤ì •í•œ íšŸìˆ˜ ì´ìƒ ë°œì£¼ëœ ë„ì„œë§Œ í•„í„°ë§í•˜ì—¬, ì¼íšŒì„± ë°œì£¼ë¥¼ ê±°ë¦…ë‹ˆë‹¤.")
        with col3:
            max_interval = int(agg_df['í‰ê·  ë°œì£¼ ê°„ê²©'].dropna().max(
            )) if not agg_df['í‰ê·  ë°œì£¼ ê°„ê²©'].isna().all() else 90
            interval_limit = st.slider("ìµœëŒ€ í‰ê·  ë°œì£¼ ê°„ê²© í•„í„°", 1, max_interval, min(
                30, max_interval), help="ë°œì£¼ ì‚¬ì´ì˜ í‰ê·  ê¸°ê°„ì´ ì—¬ê¸°ì„œ ì„¤ì •í•œ ì¼ìˆ˜ë³´ë‹¤ ì§§ì€, 'ê¾¸ì¤€í•œ' ë„ì„œë“¤ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.")

        promising_books_df = agg_df[
            (agg_df['ìµœì´ˆë°œì£¼í›„ê²½ê³¼ì¼'] <= days_since_first_limit) &
            (agg_df['ë°œì£¼íšŸìˆ˜'] >= min_freq_limit) &
            (agg_df['í‰ê·  ë°œì£¼ ê°„ê²©'].fillna(interval_limit + 1) <= interval_limit)
        ].sort_values(by='í‰ê·  ë°œì£¼ ê°„ê²©')

        st.subheader(f"í•„í„°ë§ ê²°ê³¼: ì´ {len(promising_books_df)}ê¶Œì˜ ìœ ë§ ë„ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

        # --- ê°œë³„ ë„ì„œ íŒë§¤ ì¶”ì´ ê·¸ë˜í”„ ---
        book_col_name = next(
            (col for col in df_raw.columns if 'ë„ì„œëª…' in col), 'ë„ì„œëª…')
        date_col_name = next(
            (col for col in df_raw.columns if 'ë‚ ì§œ' in col), 'ë‚ ì§œ')
        amount_col_name = next(
            (col for col in df_raw.columns if 'ë°œì£¼ëŸ‰' in col), 'ë°œì£¼ëŸ‰')

        for _, row in promising_books_df.iterrows():
            book_title = row[book_col_name]
            with st.expander(f"'{book_title}' (í‰ê·  {row['í‰ê·  ë°œì£¼ ê°„ê²©']:.1f}ì¼ ê°„ê²© / ì´ {row['ë°œì£¼íšŸìˆ˜']}íšŒ ë°œì£¼)"):
                history_df = df_raw[df_raw[book_col_name] == book_title]
                fig = px.bar(history_df, x=date_col_name,
                             y=amount_col_name, title=f"'{book_title}' ì¼ë³„ ë°œì£¼ëŸ‰ ì¶”ì´")
                fig.update_layout(yaxis_title="ë°œì£¼ëŸ‰")
                st.plotly_chart(fig, use_container_width=True)

    with tab3:
        st.header("ë°ì´í„° ì¸ì‚¬ì´íŠ¸ ì‹œê°í™”")
        date_col = next((col for col in df_raw.columns if 'ë‚ ì§œ' in col), 'ë‚ ì§œ')
        amount_col = next(
            (col for col in df_raw.columns if 'ë°œì£¼ëŸ‰' in col), 'ë°œì£¼ëŸ‰')
        grade_order = [f"{i}ë“±ê¸‰" for i in range(1, 6)]

        col1, col2 = st.columns(2)
        with col1:
            st.subheader("â‘  ì›”ë³„ ë°œì£¼ íŠ¸ë Œë“œ")
            monthly_orders = df_raw.set_index(date_col).resample('ME')[
                amount_col].sum().reset_index()
            fig_line_month = px.line(monthly_orders, x=date_col, y=amount_col, markers=True,
                                     title="ì›”ë³„ ì´ ë°œì£¼ëŸ‰ ë³€í™”", labels={date_col: 'ì›”', amount_col: 'ì´ ë°œì£¼ëŸ‰'})
            st.plotly_chart(fig_line_month, use_container_width=True)
        with col2:
            st.subheader("â‘¡ ì£¼ë³„ ë°œì£¼ íŠ¸ë Œë“œ")
            weekly_orders = df_raw.set_index(date_col).resample(
                'W-Mon')[amount_col].sum().reset_index()
            fig_line_week = px.line(weekly_orders, x=date_col, y=amount_col, markers=True,
                                    title="ì£¼ë³„ ì´ ë°œì£¼ëŸ‰ ë³€í™”", labels={date_col: 'ì£¼', amount_col: 'ì´ ë°œì£¼ëŸ‰'})
            st.plotly_chart(fig_line_week, use_container_width=True)

    with tab4:
        st.header("ì „ì²´ ë¶„ì„ ë°ì´í„°")
        display_columns = ['ë„ì„œëª…', 'ë“±ê¸‰', 'ì ìˆ˜', 'ì´ë°œì£¼ëŸ‰', 'ë°œì£¼íšŸìˆ˜',
                           'ì‹œê°„ê°€ì¤‘ì¹˜', 'í‰ê·  ë°œì£¼ ê°„ê²©', 'ìµœì´ˆë°œì£¼ì¼', 'ìµœê·¼ë°œì£¼ì¼', 'ê²½ê³¼ì¼']
        final_df = agg_df[display_columns].sort_values(
            by='ì ìˆ˜', ascending=False)
        st.dataframe(final_df, use_container_width=True)

        st.subheader("ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
        col1, col2 = st.columns(2)
        with col1:
            csv_data = final_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button("ğŸ’¾ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ", data=csv_data,
                               file_name='book_cluster_analysis.csv', mime='text/csv', use_container_width=True)
        with col2:
            excel_data = to_excel(final_df)
            st.download_button("ğŸ’¾ XLSX íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ", data=excel_data, file_name='book_cluster_analysis.xlsx',
                               mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', use_container_width=True)
